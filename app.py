import streamlit as st
import time
import getpass
from neo4j import GraphDatabase
from datetime import datetime
from typing import List, Dict, Any, Optional, TypedDict, Annotated
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import InMemoryVectorStore
from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from neo4j import GraphDatabase
from dotenv import load_dotenv
from langchain_core.documents import Document
from typing import List, Dict, Any 
import re
import requests
from datetime import datetime
from cachetools import cached, TTLCache
import graphviz 
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompts import MessagesPlaceholder
from operator import add 
import unicodedata
from langgraph.checkpoint.memory import MemorySaver
import random
import os

load_dotenv()

# --- Markdown Sanitizasyon Fonksiyonu ---
# Bu fonksiyon, herhangi bir sÄ±nÄ±fÄ±n veya ana akÄ±ÅŸÄ±n dÄ±ÅŸÄ±nda, global olarak tanÄ±mlanmalÄ±.
# Streamlit'in markdown iÅŸleyicisindeki regex hatalarÄ±nÄ± Ã¶nlemek iÃ§in daha genel bir temizlik.
def sanitize_markdown(text):
    """
    Streamlit'in markdown iÅŸleyicisinde sorun Ã§Ä±karabilecek belirli karakterleri temizler
    veya kaÃ§Ä±ÅŸ karakteri ekler. Ã–zellikle URL'lerde ve regex'lerde sorun yaratabilecek
    karakterlere odaklanÄ±r.
    """
    # URL'lerdeki parantezleri ve diÄŸer potansiyel sorunlu karakterleri temizlemeyi deneyelim
    # Markdown linklerinde Ã¶zel karakterler sorun yaratabilir.
    # Burada `(?<foo>)` gibi desenleri deÄŸil, genel markdown ve URL gÃ¼venliÄŸini hedefliyoruz.
    
    # BazÄ± Ã¶zel karakterleri kaÃ§Ä±ÅŸ karakteriyle iÅŸaretle
    # Streamlit'in kendi otolink iÅŸleyicisini bozmamak iÃ§in URL linki formatÄ± dÄ±ÅŸÄ±nda olanlarÄ± temizle
    sanitized_text = text.replace(">", "&gt;").replace("<", "&lt;") # HTML etiketlerini Ã¶nle
    
    # regex group specifier hatasÄ± iÃ§in, genel olarak `(?<` ile baÅŸlayan her ÅŸeyi temizle
    # Ancak bu, metindeki normal parantezleri de etkileyebilir.
    # EÄŸer sorun hala devam ederse, bu satÄ±rÄ± kaldÄ±rÄ±p daha az invaziv bir Ã§Ã¶zÃ¼m dÃ¼ÅŸÃ¼nebiliriz.
    sanitized_text = re.sub(r"\(\?<[^>]+>", "(", sanitized_text)
    
    # KÃ¶ÅŸeli parantez iÃ§indeki link formatlarÄ±nda sorun oluÅŸmamasÄ± iÃ§in
    # Ã¶zellikle [metin](link) veya sadece link olan durumlarda dikkatli olmalÄ±yÄ±z.
    # Genel olarak, URL'lerin doÄŸru formatta olduÄŸundan emin olmak Ã¶nemlidir.
    
    # Ekstra kontrol: EÄŸer metin iÃ§inde gerÃ§ekten `(?<name>)` gibi bir yapÄ± olmasÄ±nÄ± beklemiyorsak,
    # bu regex hala uygun olabilir. Ancak bu, `SyntaxError`'Ä±n doÄŸrudan Ã§Ã¶zÃ¼mÃ¼ olmayabilir
    # Ã§Ã¼nkÃ¼ hata JS tarafÄ±nda fÄ±rlatÄ±lÄ±yor olabilir.
    
    return sanitized_text

class Neo4jConnector:
    def __init__(self):
        self.uri = os.getenv("NEO4J_URI")
        self.user = os.getenv("NEO4J_USER")
        self.password = os.getenv("NEO4J_PASSWORD")
        self.database = os.getenv("NEO4J_DATABASE", "neo4j")
        self.driver = None

    def connect(self):
        """Establishes a connection to Neo4j."""
        if self.driver is None:
            try:
                self.driver = GraphDatabase.driver(self.uri, auth=(self.user, self.password))
                with self.driver.session(database=self.database) as session:
                    session.run("RETURN 1")
            except Exception as exc:
                st.error(f"Neo4j baÄŸlantÄ± hatasÄ±: {exc}")
                raise ConnectionError(f"Neo4j baÄŸlantÄ± hatasÄ±: {exc}") from exc

    def close(self):
        """Closes the Neo4j driver if it's open."""
        if self.driver:
            self.driver.close()
            self.driver = None

    def get_meyhaneler(self, limit: int = 10000) -> List[Dict[str, Any]]:
        """
        Fetches 'Meyhane' nodes from Neo4j in the format expected by your LangGraph app.
        """
        self.connect()
        query = """
        MATCH (m:Meyhane)
        RETURN
            m.name                  AS name,
            m.google_adres          AS address,
            m.google_ortalama_puan AS rating,
            m.google_toplam_yorum   AS review_count,
            m.maps_linki            AS map_link,
            m.google_telefon        AS phone,
            m.fiyat_seviyesi_simge AS price_level,
            elementId(m)            AS neo4j_element_id
        ORDER BY m.google_ortalama_puan DESC
        LIMIT $limit
        """
        try:
            with self.driver.session(database=self.database) as session:
                result = session.run(query, limit=limit)
                return [self._clean_record(record) for record in result]
        except Exception as exc:
            st.error(f"Neo4j sorgu hatasÄ± (get_meyhaneler): {exc}")
            print(f"Sorgu hatasÄ± (get_meyhaneler): {exc}")
            return []

    @staticmethod
    def _clean_record(record) -> Dict[str, Any]:
        """
        Cleans Neo4j record by replacing None values with defaults
        and ensuring correct types for numeric fields.
        """
        name = record.get("name") or "Bilinmiyor"
        address = record.get("address") or "Adres yok"
        rating_value = record.get("rating")
        rating = float(rating_value) if rating_value is not None else 0.0
        review_count_value = record.get("review_count")
        review_count = int(review_count_value) if review_count_value is not None else 0
        map_link = record.get("map_link") or ""
        phone = record.get("phone") or ""
        price_level = record.get("price_level") or ""
        neo4j_element_id = record["neo4j_element_id"]

        return {
            "name": name,
            "address": address,
            "rating": rating,
            "review_count": review_count,
            "map_link": map_link,
            "phone": phone,
            "price_level": price_level,
            "neo4j_element_id": neo4j_element_id,
        }

# --- LangGraph State TanÄ±mlamasÄ± ---
def add_messages(left: List[BaseMessage], right: List[BaseMessage]) -> List[BaseMessage]:
    """Combines two lists of BaseMessage, used for state annotation."""
    return left + right

class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    last_recommended_place: Optional[str]
    next_node: Optional[str]
    location_query: Optional[str]

def process_documents(docs: List[Any]) -> List[Document]:
    processed = []
    for doc in docs:
        if isinstance(doc, dict):
            metadata = {
                "Mekan AdÄ±": doc.get("name", "Bilinmeyen Mekan"),
                "Adres": doc.get("address", "Bilinmeyen Adres"),
                "Google PuanÄ±": str(doc.get("rating", 0.0)),
                "Google Yorum SayÄ±sÄ±": str(doc.get("review_count", 0)),
                "Maps Linki": doc.get("map_link", "Harita linki yok"),
                "Telefon": doc.get("phone", "Yok"),
                "Fiyat Seviyesi": str(doc.get("price_level", "Yok"))
            }
            main_content = (
                f"Mekan AdÄ±: {metadata['Mekan AdÄ±']}, "
                f"Adres: {metadata['Adres']}, "
                f"Google PuanÄ±: {metadata['Google PuanÄ±']}, "
                f"Google Yorum SayÄ±sÄ±: {metadata['Google Yorum SayÄ±sÄ±']}, "
                f"Fiyat Seviyesi: {metadata['Fiyat Seviyesi']}"
            )
            processed.append(Document(
                page_content=main_content,
                metadata=metadata
            ))
    return processed

# --- Neo4j Verilerini YÃ¼kle ve VektÃ¶r Deposunu OluÅŸtur (Sadece Bir Kez Ã‡alÄ±ÅŸtÄ±r) ---
@st.cache_resource
def initialize_retriever():
    try:
        conn = Neo4jConnector()
        meyhaneler_listesi = conn.get_meyhaneler(limit=10000) 
        conn.close()
        if not meyhaneler_listesi:
            st.warning("UyarÄ±: Neo4j'den hiÃ§ mekan verisi Ã§ekilemedi. Retrieval boÅŸ sonuÃ§ dÃ¶nebilir. Dummy veri kullanÄ±lÄ±yor.")
            meyhaneler_listesi = [
                {"name": "Dummy Meyhane A", "address": "Dummy Adres A", "rating": 4.0, "review_count": 100, "map_link": "http://dummy.map.a", "phone": "000", "price_level": 2, "neo4j_element_id": "dummy-a"},
                {"name": "Dummy Meyhane B", "address": "Dummy Adres B", "rating": 4.5, "review_count": 250, "map_link": "http://dummy.map.b", "phone": "000", "price_level": 3, "neo4j_element_id": "dummy-b"},
                {"name": "Dummy Meyhane C", "address": "Dummy Adres C", "rating": 3.8, "review_count": 50, "map_link": "http://dummy.map.c", "phone": "000", "price_level": 1, "neo4j_element_id": "dummy-c"},
            ]
    except Exception as e:
        st.error(f"Neo4j'den veri Ã§ekerken hata oluÅŸtu: {e}. LÃ¼tfen Neo4j sunucunuzun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan ve kimlik bilgilerinin doÄŸru olduÄŸundan emin olun. Dummy veri kullanÄ±lÄ±yor.")
        meyhaneler_listesi = [
            {"name": "Dummy Meyhane A", "address": "Dummy Adres A", "rating": 4.0, "review_count": 100, "map_link": "http://dummy.map.a", "phone": "000", "price_level": 2, "neo4j_element_id": "dummy-a"},
            {"name": "Dummy Meyhane B", "address": "Dummy Adres B", "rating": 4.5, "review_count": 250, "map_link": "http://dummy.map.b", "phone": "000", "price_level": 3, "neo4j_element_id": "dummy-b"},
            {"name": "Dummy Meyhane C", "address": "Dummy Adres C", "rating": 3.8, "review_count": 50, "map_link": "http://dummy.map.c", "phone": "000", "price_level": 1, "neo4j_element_id": "dummy-c"},
        ]
    
    processed_docs = process_documents(meyhaneler_listesi)
    vectorstore = InMemoryVectorStore.from_documents(
        documents=processed_docs,
        embedding=OpenAIEmbeddings()
    )
    return vectorstore.as_retriever(search_kwargs={"k": 5})

retriever = initialize_retriever()

# --- LLM ve Prompt TanÄ±mlamalarÄ± ---
SYSTEM_PROMPT = """Sen Ä°stanbul'da romantik mekan, meyhane, restoran ve kafe Ã¶nerisi yapabilen bir AI asistanÄ±sÄ±n.
KullanÄ±cÄ±ya Google haritalar bilgileriyle desteklenmiÅŸ, hava durumuyla uyumlu Ã¶nerilerde bulunabilirsin.
Gelen sorulara doÄŸal, nazik ve samimi bir dille cevap ver ve tÃ¼m cevaplarÄ±n TÃ¼rkÃ§e olsun.

AÅŸaÄŸÄ±daki gibi konuÅŸmalar seni yÃ¶nlendirmelidir:
- 'BeÅŸiktaÅŸâ€™ta romantik bir mekan var mÄ±?' â†’ Mekan aramasÄ± yap
- 'YarÄ±n BeÅŸiktaÅŸ'ta hava nasÄ±l olacak?' â†’ Hava durumu kontrol et
- 'Bir ilginÃ§ bilgi ver' â†’ EÄŸlenceli bir bilgi paylaÅŸ
- 'Merhaba', 'Selam' â†’ KarÅŸÄ±lama mesajÄ± gÃ¶nder

KullandÄ±ÄŸÄ±n veritabanÄ±nda yer alan mekanlar sadece Ä°stanbul sÄ±nÄ±rlarÄ± iÃ§indedir.
EÄŸer kullanÄ±cÄ± baÅŸka ÅŸehirde mekan istiyorsa, bunu aÃ§Ä±kÃ§a belirtmelisin."""

SUMMARY_PROMPT = ChatPromptTemplate.from_messages([
    ("system", "Sohbet geÃ§miÅŸini kÄ±sa ve Ã¶z ÅŸekilde Ã¶zetle. Sadece Ã¶nemli bilgileri korla."),
    MessagesPlaceholder(variable_name="messages"),
])

# --- YardÄ±mcÄ± Fonksiyonlar ---
@cached(TTLCache(maxsize=100, ttl=3600))
def get_fun_fact() -> str:
    try:
        response = requests.get("https://uselessfacts.jsph.pl/api/v2/facts/random?language=tr", timeout=5)
        if response.status_code == 200:
            return response.json().get("text", "Ä°lginÃ§ bir bilgi bulunamadÄ±.")
        return "BugÃ¼n iÃ§in ilginÃ§ bir bilgi yok."
    except Exception:
        return "Ä°lginÃ§ bilgi servisi ÅŸu an Ã§alÄ±ÅŸmÄ±yor."

def clean_location_query(query: str) -> str:
    normalized_query = unicodedata.normalize('NFKD', query.lower()).encode('ascii', 'ignore').decode('utf-8')

    istanbul_locations = [
        r'etiler', r'levent', r'maslak', r'nisantasi', r'nisantaÅŸi', 
        r'bebek', r'arnavutkoy', r'arnavutkÃ¶y', r'ortakoy', r'ortakÃ¶y', r'cihangir',
        r'taksim', r'karakoy', r'karakÃ¶y', r'galata', r'fatih',
        r'sultanahmet', r'eminonu', r'eminÃ¶nÃ¼', r'kadikoy', r'kadÄ±kÃ¶y', r'moda',
        r'bagdat caddesi', r'baÄŸdat caddesi', r'suadiye', r'bostanci', r'bostancÄ±',
        r'maltepe', r'kartal', r'pendik', r'uskudar', r'Ã¼skÃ¼dar',
        r'camlica', r'Ã§amlÄ±ca', r'beykoz', r'atasehir', r'ataÅŸehir', r'cekmekoy', r'Ã§ekmekÃ¶y',
        r'sariyer', r'sarÄ±yer', r'istinye', r'tarabya', r'yenikoy', r'yenikÃ¶y',
        r'bahcekoy', r'bahÃ§ekÃ¶y', r'buyukdere', r'bÃ¼yÃ¼kdere', r'zumrutevler', r'zÃ¼mrÃ¼tevler',
        r'florya', r'yesilkoy', r'yeÅŸilkÃ¶y', r'yesilyurt', 'yeÅŸilyurt', r'bakirkoy', r'bakÄ±rkÃ¶y',
        r'atakoy', r'atakÃ¶y', r'zeytinburnu', r'gungoren', r'gÃ¼ngÃ¶ren', r'esenler',
        r'bayrampasa', r'bayrampaÅŸa', r'gaziosmanpasa', r'gaziosmanpaÅŸa', r'eyup', r'eyÃ¼p', r'kagithane', r'kaÄŸÄ±thane',
        r'sisli', r'ÅŸiÅŸli', r'besiktas', r'beÅŸiktaÅŸ', r'avcilar', r'avcÄ±lar', r'beylikduzu', 'beylikdÃ¼zÃ¼',
        r'esenyurt', r'buyukcekmece', r'bÃ¼yÃ¼kÃ§ekmece', r'silivri', r'catalca', r'Ã§atalca',
        r'sile', r'ÅŸile', r'agva', r'aÄŸva', r'adalar', r'basaksehir', 'baÅŸakÅŸehir',
        r'bahcelievler', r'bahÃ§elievler', r'kucukcekmece', r'kÃ¼Ã§Ã¼kÃ§ekmece', r'cankurtaran' 
    ]

    for loc_regex in istanbul_locations:
        match = re.search(r'\b' + loc_regex + r'\b', normalized_query)
        if match:
            return match.group(0)

    general_cities = [
        r'istanbul', r'ankara', r'izmir', r'adana',
        r'bursa', r'antalya', r'konya', r'kayseri',
        r'gaziantep', r'samsun', r'eskisehir', r'eskiÅŸehir', r'duzce', r'dÃ¼zce'
    ]

    for city_regex in general_cities:
        match = re.search(r'\b' + city_regex + r'\b', normalized_query)
        if match:
            return match.group(0)

    return "istanbul"

weather_cache = TTLCache(maxsize=100, ttl=300)

@cached(weather_cache)
def get_openweather_forecast(location: str) -> Dict:
    api_key = os.getenv("OPENWEATHER_API_KEY")
    if not api_key:
        return {"error": "API anahtarÄ± bulunamadÄ±."}
    try:
        geo = requests.get(
            f"http://api.openweathermap.org/geo/1.0/direct?q={location},TR&limit=1&appid={api_key}",
            timeout=10,
        ).json()
        if not geo:
            return {"error": f"'{location}' konumu bulunamadÄ±."}
        lat, lon = geo[0]["lat"], geo[0]["lon"]
        weather = requests.get(
            f"https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={api_key}&units=metric&lang=tr",
            timeout=10,
        ).json()
        return weather
    except requests.exceptions.RequestException as e:
        return {"error": f"API hatasÄ±: {e}"}

def format_weather_response(location: str, data: Dict) -> str:
    if "error" in data:
        return f"âŒ {data['error']}"
    try:
        lines = [f"ğŸŒ¤ï¸ **{location.capitalize()} Hava Durumu Tahmini:**"]
        if "list" not in data or not data["list"]:
            return f"âŒ {location.capitalize()} iÃ§in hava durumu tahmini bulunamadÄ±."

        for item in data.get("list", [])[:8]: # Sonraki 24 saat iÃ§in (3 saatte bir)
            dt = datetime.strptime(item["dt_txt"], "%Y-%m-%d %H:%M:%S")
            lines.append(
                f"â€¢ {dt:%d/%m %H:%M}: "
                f"{item['weather'][0]['description'].capitalize()}, "
                f"SÄ±caklÄ±k: {item['main']['temp']}Â°C, "
                f"Hissedilen: {item['main']['feels_like']}Â°C, "
                f"Nem: {item['main']['humidity']}%, "
                f"RÃ¼zgar: {item['wind']['speed']} m/s"
            )
        return "\n".join(lines)
    except Exception as e:
        return f"âŒ Hava durumu verisi iÅŸlenirken hata oluÅŸtu: {e}"

# --- LangGraph Nodes ---
def check_weather_node(state: AgentState) -> AgentState:
    last_msg = state["messages"][-1]
    query = last_msg.content

    location = state.get("location_query") or clean_location_query(query)
    state["location_query"] = location 

    formatted = format_weather_response(location, get_openweather_forecast(location))

    sanitized_formatted = sanitize_markdown(formatted)
    state["messages"].append(AIMessage(content=sanitized_formatted))
    state["messages"].append(AIMessage(content=formatted))
    return state

def add_system_message(state: AgentState) -> AgentState:
    system_msg = SystemMessage(content=SYSTEM_PROMPT)
    
    if not any(isinstance(msg, SystemMessage) for msg in state["messages"]):
        return {"messages": [system_msg] + state["messages"]}
    else:
        return state

def summarize_conversation(state: AgentState) -> AgentState:
    messages = state["messages"]

    if len(messages) > 5: # KonuÅŸma belirli bir uzunluÄŸu aÅŸÄ±nca Ã¶zetle
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
        chain = SUMMARY_PROMPT | llm
        summary = chain.invoke({"messages": messages})

        return {
            "messages": [
                SystemMessage(content=SYSTEM_PROMPT),
                AIMessage(content=summary.content) 
            ]
        }
    else:
        return state

def search_meyhaneler_node(state: AgentState) -> AgentState:
    last_msg = state["messages"][-1]
    query = last_msg.content

    location = clean_location_query(query)
    state["location_query"] = location 

    try:
        # Arama sorgusunu iyileÅŸtir
        retrieval_query = f"{location} {query}" if location and location not in query.lower() else query
        raw_results = retriever.invoke(retrieval_query, k=10) # Daha fazla sonuÃ§ alÄ±p filtreleyelim
        filtered_results = []

        normalized_location = unicodedata.normalize('NFKD', location.lower()).encode('ascii', 'ignore').decode('utf-8')

        # Konuma gÃ¶re filtreleme
        for doc in raw_results:
            address_lower = unicodedata.normalize('NFKD', doc.metadata.get("Adres", "").lower()).encode('ascii', 'ignore').decode('utf-8')
            name_lower = unicodedata.normalize('NFKD', doc.metadata.get("Mekan AdÄ±", "").lower()).encode('ascii', 'ignore').decode('utf-8')
            
            # EÄŸer konum sorguda yer alÄ±yorsa ve mekanÄ±n adresi veya adÄ± bu konumu iÃ§eriyorsa ekle
            if normalized_location in address_lower or normalized_location in name_lower:
                filtered_results.append(doc)
        
        # EÄŸer filtrelemeden sonra hala sonuÃ§ yoksa veya ilk 3 sonuÃ§ yoksa daha geniÅŸ arama yap
        if not filtered_results or len(filtered_results) < 3:
            # Sadece Ä°stanbul iÃ§in genel arama
            raw_results_istanbul = retriever.invoke(f"istanbul {query}", k=5)
            # Daha Ã¶nce filtrelenmiÅŸ sonuÃ§larÄ± da ekle, mÃ¼kerrerleri Ã¶nle
            seen_names = {doc.metadata.get("Mekan AdÄ±") for doc in filtered_results}
            for doc in raw_results_istanbul:
                if doc.metadata.get("Mekan AdÄ±") not in seen_names:
                    filtered_results.append(doc)
                    seen_names.add(doc.metadata.get("Mekan AdÄ±"))


        if not filtered_results:
            fallback_message = f"âŒ ÃœzgÃ¼nÃ¼m, **{location.capitalize()}** bÃ¶lgesinde aradÄ±ÄŸÄ±nÄ±z kriterlere uygun bir mekan bulamadÄ±m."
            if location == "istanbul": 
                fallback_message += " VeritabanÄ±mÄ±zda genel olarak Ä°stanbul'da bu kriterlere uygun bir mekan bulamadÄ±m."
            else: 
                fallback_message += " Belki aradÄ±ÄŸÄ±nÄ±z konumdaki verilerimiz eksiktir veya o bÃ¶lgede kriterlerinize uyan bir yer yoktur. LÃ¼tfen farklÄ± bir bÃ¶lge veya daha genel bir arama yapmayÄ± deneyin."
            
            sanitized_fallback_message = sanitize_markdown(fallback_message)
            state["messages"].append(AIMessage(content=sanitized_fallback_message))
            state["messages"].append(AIMessage(content=fallback_message))
            return state

        # Sadece ilk 5 sonucu gÃ¶ster
        formatted_results = []
        for doc in filtered_results[:5]: # Ä°lk 5 sonuÃ§la sÄ±nÄ±rla
            metadata = doc.metadata
            name = metadata.get("Mekan AdÄ±", "Bilinmeyen Mekan")
            rating = float(metadata.get("Google PuanÄ±", 0.0))
            review_count = int(metadata.get("Google Yorum SayÄ±sÄ±", 0))
            address = metadata.get("Adres", "Bilinmiyor")
            map_link = metadata.get("Maps Linki", "")
            phone = metadata.get("Telefon", "Yok")
            price_level_raw = metadata.get("Fiyat Seviyesi", "Yok")

            rating_display = f"â­ {rating:.1f}" if rating > 0 else "â­ DeÄŸerlendirilmemiÅŸ"
            review_count_display = f"({review_count} yorum)" if review_count > 0 else "(Yorum yok)"
            phone_display = f"ğŸ“ Telefon: {phone}" if phone and phone != "Yok" else ""
            
            price_display = ""
            if isinstance(price_level_raw, (int, float)):
                price_display = f"ğŸ’¸ Fiyat Seviyesi: {'â‚º' * int(price_level_raw)}"
            elif isinstance(price_level_raw, str) and price_level_raw.isdigit():
                 price_display = f"ğŸ’¸ Fiyat Seviyesi: {'â‚º' * int(price_level_raw)}"
            elif isinstance(price_level_raw, str) and price_level_raw != "Yok":
                 price_display = f"ğŸ’¸ Fiyat Seviyesi: {price_level_raw}"

            result_entry = (
                f"ğŸ  **{name}**\n"
                f"{rating_display} {review_count_display}\n"
                f"ğŸ“ {address}\n"
                f"{phone_display}\n"
                f"{price_display}\n"
                f"ğŸ”— {map_link if map_link else 'Harita linki yok'}\n"
                "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•"
            )
            formatted_results.append(result_entry)

        sanitized_content = sanitize_markdown("\n".join(formatted_results))
        state["messages"].append(AIMessage(content=sanitized_content))
        return state
    except Exception as e:
        print(f"DEBUG ERROR in search_meyhaneler_node: {e}")
        sanitized_error_message = sanitize_markdown(f"âš ï¸ Arama sÄ±rasÄ±nda beklenmedik bir hata oluÅŸtu: {str(e)}")
        state["messages"].append(AIMessage(content=sanitized_error_message))
        state["messages"].append(AIMessage(content="\n".join(formatted_results)))
        return state
    except Exception as e:
        print(f"DEBUG ERROR in search_meyhaneler_node: {e}")
        state["messages"].append(AIMessage(content=f"âš ï¸ Arama sÄ±rasÄ±nda beklenmedik bir hata oluÅŸtu: {str(e)}"))
        return state

def router_node(state: AgentState) -> AgentState:
    last_msg = state["messages"][-1]
    content = last_msg.content.lower()
    
    if any(t in content for t in ["meyhane", "restoran", "kafe", "date", "randevu", "mekan", "Ã¶neri", "neresi", "yer", "yemek", "iÃ§ki"]):
        state["next_node"] = "search"
    elif any(t in content for t in ["hava", "weather", "sÄ±caklÄ±k", "nem", "yaÄŸmur", "aÃ§Ä±k", "kapalÄ±", "derece"]):
        state["next_node"] = "weather"
    elif any(t in content for t in ["fun fact", "ilginÃ§ bilgi", "bilgi ver", "biliyor muydun", "merak", "gerÃ§ek"]):
        state["next_node"] = "fun_fact"
    else:
        state["next_node"] = "general"
    return state

def fun_fact_node(state: AgentState) -> AgentState:
    fact = get_fun_fact()

    sanitized_fact = sanitize_markdown(f"ğŸ¤” Ä°lginÃ§ Bilgi: {fact}")
    state["messages"].append(AIMessage(content=sanitized_fact))
    state["messages"].append(AIMessage(content=f"ğŸ¤” Ä°lginÃ§ Bilgi: {fact}"))
    return state

def general_response_node(state: AgentState) -> AgentState:
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

    try:
        human_messages = [msg for msg in state["messages"] if isinstance(msg, HumanMessage)]
        if human_messages:
            last_query = human_messages[-1].content.lower()

            # KarÅŸÄ±lama mesajlarÄ±
            greeting_triggers = ["selam", "merhaba", "gÃ¼naydÄ±n", "naber", "nasÄ±lsÄ±n", "hi", "alo"]
            if any(g in last_query for g in greeting_triggers):
                responses = [
                    "Merhaba! ğŸ‘‹ Ä°stanbul'da romantik mekan, meyhane, restoran ya da kafe Ã¶nerisi almak ister misin?",
                    "Selam! Size nasÄ±l yardÄ±mcÄ± olabilirim? Hava durumu bilgisi veya mekan Ã¶nerisi alabilirsiniz. ğŸ™ï¸",
                    "GÃ¼naydÄ±n! â˜€ï¸ Hangi mekan ya da hava durumu bilgisiyle yardÄ±mcÄ± olayÄ±m?",
                    "NasÄ±lsÄ±n? Ä°stanbul'da nereye gitmek istersin? Romantik bir mekan mÄ±, meyhane mi? ğŸ·"
                ]
                chosen = random.choice(responses)
                state["messages"].append(AIMessage(content=chosen))
                return state

        response = llm.invoke(state["messages"])
        if response and hasattr(response, "content") and response.content:
            sanitized_content = sanitize_markdown(response.content)
            state["messages"].append(AIMessage(content=sanitized_content))
        else:
            sanitized_fallback = sanitize_markdown("Merhaba! Size nasÄ±l yardÄ±mcÄ± olabilirim?")
            state["messages"].append(AIMessage(content=sanitized_fallback))
    
    except Exception as e:
        sanitized_error = sanitize_markdown(f"âš ï¸ Hata: {str(e)}")
        state["messages"].append(AIMessage(content=sanitized_error))
        if response and hasattr(response, "content") and response.content:
            state["messages"].append(AIMessage(content=response.content))
        else:
            state["messages"].append(AIMessage(content="Merhaba! Size nasÄ±l yardÄ±mcÄ± olabilirim?"))
    
    except Exception as e:
        state["messages"].append(AIMessage(content=f"âš ï¸ Arama sÄ±rasÄ±nda beklenmedik bir hata oluÅŸtu: {str(e)}"))

    return state


@st.cache_resource
def create_workflow():
    workflow = StateGraph(AgentState)
    workflow.add_node("add_system_message", add_system_message)
    workflow.add_node("router", router_node)
    workflow.add_node("search", search_meyhaneler_node)
    workflow.add_node("weather", check_weather_node)
    workflow.add_node("general", general_response_node)
    workflow.add_node("fun_fact", fun_fact_node)
    workflow.add_node("summarize", summarize_conversation) 
    
    workflow.add_edge(START, "add_system_message")
    workflow.add_edge("add_system_message", "router")
    
    workflow.add_conditional_edges(
        "router",
        lambda state: state["next_node"], 
        {
            "search": "search",
            "weather": "weather",
            "general": "general",
            "fun_fact": "fun_fact",
        }
    )

    workflow.add_edge("search", END)
    workflow.add_edge("weather", END)
    workflow.add_edge("fun_fact", END)
    
    workflow.add_conditional_edges(
        "general",
        lambda state: "summarize" if len(state["messages"]) > 5 else END, 
        {
            "summarize": "summarize", 
            END: END 
        }
    )
    workflow.add_edge("summarize", END) 

    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)

    return graph

# --- STREAMLIT UYGULAMASI ---
st.set_page_config(page_title="Ä°stanbul Mekan AsistanÄ± ğŸ’¬", page_icon="ğŸŒƒ")

st.title("Ä°stanbul Mekan AsistanÄ± ğŸ’¬")
st.markdown("Merhaba! Ben Ä°stanbul'daki romantik mekan, meyhane, restoran ve kafe Ã¶nerileri sunan yapay zeka asistanÄ±yÄ±m. AyrÄ±ca hava durumu bilgisi veya ilginÃ§ bilgiler de saÄŸlayabilirim. Size nasÄ±l yardÄ±mcÄ± olabilirim? ğŸ˜Š")

# API AnahtarlarÄ±nÄ±n ayarlÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et
if not os.getenv("OPENAI_API_KEY") or not os.getenv("OPENWEATHER_API_KEY"):
    st.error("âš ï¸ API anahtarlarÄ± eksik! LÃ¼tfen `os.environ` iÃ§inde `OPENAI_API_KEY` ve `OPENWEATHER_API_KEY` deÄŸiÅŸkenlerini ayarlayÄ±n.")
    st.stop() # UygulamayÄ± durdur

# LangGraph'Ä± baÅŸlat (sadece bir kez)
if "graph" not in st.session_state:
    st.session_state.graph = create_workflow()
if "conversation_thread_id" not in st.session_state:
    st.session_state.conversation_thread_id = "user_session_streamlit_" + str(random.randint(1000, 9999))
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Merhaba! ğŸ‘‹ Ä°stanbul'da mekan, hava durumu veya eÄŸlenceli bir bilgi arÄ±yorsan buradayÄ±m!"}]


# Sohbet geÃ§miÅŸini gÃ¶rÃ¼ntÃ¼le
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(sanitize_markdown(message["content"]))
        st.markdown(message["content"])


# KullanÄ±cÄ±dan girdi al
if prompt := st.chat_input("MesajÄ±nÄ±zÄ± buraya yazÄ±n..."):
    # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle ve gÃ¶rÃ¼ntÃ¼le
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # LangGraph'Ä± Ã§alÄ±ÅŸtÄ±rma
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # Sadece son kullanÄ±cÄ± mesajÄ±nÄ± gÃ¶nder
        initial_state = {
            "messages": [HumanMessage(content=prompt)],
            "last_recommended_place": None,
            "next_node": None
        }

        # LangGraph akÄ±ÅŸÄ±nÄ± Ã§aÄŸÄ±rÄ±n
        try:
            graph_config = {"configurable": {"thread_id": st.session_state.conversation_thread_id}}
            
            # LangGraph stream metodunu kullanarak yanÄ±tÄ± parÃ§a parÃ§a alÄ±n
            for s in st.session_state.graph.stream(initial_state, config=graph_config):
                for key in s:
                    node_output = s[key]
                    if "messages" in node_output:
                        for msg in reversed(node_output["messages"]): 
                            if isinstance(msg, AIMessage) and msg.content:
                                # YanÄ±tÄ± karakter karakter gÃ¶stermek iÃ§in
                                for chunk in msg.content.split(): 
                                    full_response += chunk + " "
                                    time.sleep(0.02) 
                                    # Buradaki geÃ§ici Ã§Ä±ktÄ±yÄ± da sanitize edebiliriz
                                    message_placeholder.markdown(sanitize_markdown(full_response) + "â–Œ") 

                                # TamamlanmÄ±ÅŸ yanÄ±tÄ± gÃ¶stermeden ve kaydetmeden Ã¶nce sanitize et
                                sanitized_final_response = sanitize_markdown(msg.content) # msg.content'i kullan
                                message_placeholder.markdown(sanitized_final_response) 
                                st.session_state.messages.append({"role": "assistant", "content": msg.content}) # Orijinal mesajÄ± kaydet
                                break # Sadece ilk AI mesajÄ±nÄ± al
                    if full_response:
                        break # Ä°Ã§ dÃ¶ngÃ¼yÃ¼ kÄ±r
                if full_response:
                    break # DÄ±ÅŸ dÃ¶ngÃ¼yÃ¼ de kÄ±r

            # EÄŸer hiÃ§bir AI mesajÄ± bulunamadÄ±ysa bir fallback mesajÄ± gÃ¶nder
            if not full_response: 
                fallback_message = "ÃœzgÃ¼nÃ¼m, isteÄŸinizi anlayamadÄ±m veya ÅŸu an yanÄ±t veremiyorum. Daha spesifik bir ÅŸey mi denemek istersiniz?"
                sanitized_fallback_message = sanitize_markdown(fallback_message) # Fallback mesajÄ±nÄ± da sanitize et
                message_placeholder.markdown(sanitized_fallback_message)
                st.session_state.messages.append({"role": "assistant", "content": fallback_message}) # Orijinal mesajÄ± kaydet

        except Exception as e:
            error_message = f"Beklenmedik bir hata oluÅŸtu: {str(e)}\nLÃ¼tfen daha sonra tekrar deneyin."
            sanitized_error_message = sanitize_markdown(error_message) # Hata mesajÄ±nÄ± da sanitize et
            st.session_state.messages.append({"role": "assistant", "content": error_message}) # Orijinal mesajÄ± kaydet
            st.error(sanitized_error_message)