import streamlit as st
import time
import getpass
from neo4j import GraphDatabase
from datetime import datetime
from typing import List, Dict, Any, Optional, TypedDict, Annotated
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import InMemoryVectorStore
from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from neo4j import GraphDatabase
# Removed: from dotenv import load_dotenv
from langchain_core.documents import Document
from typing import List, Dict, Any
import re
import requests
from datetime import datetime
from cachetools import cached, TTLCache
import graphviz
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompts import MessagesPlaceholder
from operator import add
import unicodedata
from langgraph.checkpoint.memory import MemorySaver
import random
import os
import uuid

try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    OPENWEATHER_API_KEY = st.secrets["OPENWEATHER_API_KEY"]
    TAVILY_API_KEY = st.secrets["TAVILY_API_KEY"]
    URI = st.secrets["NEO4J_URI"]
    USERNAME = st.secrets["NEO4J_USER"]
    PASSWORD = st.secrets["NEO4J_PASSWORD"]
    NEO4J_DATABASE = st.secrets.get("NEO4J_DATABASE", "neo4j")

except KeyError as e:
    st.error(f"Eksik Streamlit sÄ±rrÄ±: {e}. LÃ¼tfen Streamlit Cloud kontrol panelinizde yapÄ±landÄ±rÄ±n.")
    st.stop()


def sanitize_markdown(text):
    if not isinstance(text, str):

        return str(text)
    if not text:
        return ""

    text = text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
    markdown_chars = ['\\', '*', '_', '~', '`', '#', '[', ']', '(', ')', '{', '}', '!', '^']
    for char in markdown_chars:
        text = text.replace(char, f"\\{char}")

    return text


def safe_markdown(text):
    try:

        re.compile(text)
        return text
    except re.error:

        return f"<pre>{text}</pre>"


class Neo4jConnector:
    def __init__(self):

        self.uri = st.secrets["NEO4J_URI"] 
        self.user = st.secrets["NEO4J_USER"] 
        self.password = st.secrets["NEO4J_PASSWORD"] 
        self.database = st.secrets.get("NEO4J_DATABASE", "neo4j")
        self.driver = None

    def connect(self):
        """Establishes a connection to Neo4j."""
        if self.driver is None:
            try:
                self.driver = GraphDatabase.driver(self.uri, auth=(self.user, self.password))
                with self.driver.session(database=self.database) as session:
                    session.run("RETURN 1")
            except Exception as exc:
                st.error(f"Neo4j baÄŸlantÄ± hatasÄ±: {exc}")
                raise ConnectionError(f"Neo4j baÄŸlantÄ± hatasÄ±: {exc}") from exc

    def close(self):
        """Closes the Neo4j driver if it's open."""
        if self.driver:
            self.driver.close()
            self.driver = None


    def get_meyhaneler(self, limit: int = 10000) -> List[Dict[str, Any]]:
        """
        Fetches 'Meyhane' nodes from Neo4j in the format expected by your LangGraph app.
        """
        self.connect()
        query = """
        MATCH (m:Meyhane)
        RETURN
            m.name                  AS name,
            m.google_adres          AS address,
            m.google_ortalama_puan AS rating,
            m.google_toplam_yorum   AS review_count,
            m.maps_linki            AS map_link,
            m.google_telefon        AS phone,
            m.fiyat_seviyesi_simge AS price_level,
            elementId(m)            AS neo4j_element_id
        ORDER BY m.google_ortalama_puan DESC
        LIMIT $limit
        """
        try:
            with self.driver.session(database=self.database) as session:
                result = session.run(query, limit=limit)
                records = [self._clean_record(record) for record in result]
                return records
        except Exception as exc:
            st.error(f"Neo4j sorgu hatasÄ± (get_meyhaneler): {exc}")
            print(f"Sorgu hatasÄ± (get_meyhaneler): {exc}")
            return []

    @staticmethod
    def _clean_record(record) -> Dict[str, Any]:
        """
        Cleans Neo4j record by replacing None values with defaults
        and ensuring correct types for numeric fields.
        """
        name = record.get("name") or "Bilinmiyor"
        address = record.get("address") or "Adres yok"
        rating_value = record.get("rating")
        rating = float(rating_value) if rating_value is not None else 0.0
        review_count_value = record.get("review_count")
        review_count = int(review_count_value) if review_count_value is not None else 0
        map_link = record.get("map_link") or ""
        phone = record.get("phone") or ""
        price_level = record.get("price_level") or ""
        neo4j_element_id = record["neo4j_element_id"]

        return {
            "name": name,
            "address": address,
            "rating": rating,
            "review_count": review_count,
            "map_link": map_link,
            "phone": phone,
            "price_level": price_level,
            "neo4j_element_id": neo4j_element_id,
        }

def add_messages(left: List[BaseMessage], right: List[BaseMessage]) -> List[BaseMessage]:
    """Combines two lists of BaseMessage, used for state annotation."""
    return left + right

class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    last_recommended_place: Optional[str]
    next_node: Optional[str]
    location_query: Optional[str]

def process_documents(docs: List[Any]) -> List[Document]:
    processed = []
    for doc in docs:
        if isinstance(doc, dict):
            metadata = {
                "Mekan AdÄ±": doc.get("name", "Bilinmeyen Mekan"),
                "Adres": doc.get("address", "Bilinmeyen Adres"),
                "Google PuanÄ±": str(doc.get("rating", 0.0)),
                "Google Yorum SayÄ±sÄ±": str(doc.get("review_count", 0)),
                "Maps Linki": doc.get("map_link", "Harita linki yok"),
                "Telefon": doc.get("phone", "Yok"),
                "Fiyat Seviyesi": str(doc.get("price_level", "Yok"))
            }
            main_content = (
                f"Mekan AdÄ±: {metadata['Mekan AdÄ±']}, "
                f"Adres: {metadata['Adres']}, "
                f"Google PuanÄ±: {metadata['Google PuanÄ±']}, "
                f"Google Yorum SayÄ±sÄ±: {metadata['Google Yorum SayÄ±sÄ±']}, "
                f"Fiyat Seviyesi: {metadata['Fiyat Seviyesi']}"
            )
            processed.append(Document(
                page_content=main_content,
                metadata=metadata
            ))
   
    return processed

@st.cache_resource
def initialize_retriever():
    meyhaneler_listesi = []
    try:
        conn = Neo4jConnector()
        meyhaneler_listesi = conn.get_meyhaneler(limit=10000)
        conn.close()
        if not meyhaneler_listesi:
            st.warning("UyarÄ±: Neo4j'den hiÃ§ mekan verisi Ã§ekilemedi. Dummy veri kullanÄ±lÄ±yor.")
            meyhaneler_listesi = [
                {"name": "Dummy Meyhane A", "address": "Dummy Adres A", "rating": 4.0, "review_count": 100, "map_link": "http://dummy.map.a", "phone": "000", "price_level": 2, "neo4j_element_id": "dummy-a"},
                {"name": "Dummy Meyhane B", "address": "Dummy Adres B", "rating": 4.5, "review_count": 250, "map_link": "http://dummy.map.b", "phone": "000", "price_level": 3, "neo4j_element_id": "dummy-b"},
                {"name": "Dummy Meyhane C", "address": "Dummy Adres C", "rating": 3.8, "review_count": 50, "map_link": "http://dummy.map.c", "phone": "000", "price_level": 1, "neo4j_element_id": "dummy-c"},
            ]

        else:
            pass
    except Exception as e:
        st.error(f"Neo4j'den veri Ã§ekerken hata oluÅŸtu: {e}. LÃ¼tfen Neo4j sunucunuzun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan ve kimlik bilgilerinin doÄŸru olduÄŸundan emin olun. Dummy veri kullanÄ±lÄ±yor.")
        meyhaneler_listesi = [
            {"name": "Dummy Meyhane A", "address": "Dummy Adres A", "rating": 4.0, "review_count": 100, "map_link": "http://dummy.map.a", "phone": "000", "price_level": 2, "neo4j_element_id": "dummy-a"},
            {"name": "Dummy Meyhane B", "address": "Dummy Adres B", "rating": 4.5, "review_count": 250, "map_link": "http://dummy.map.b", "phone": "000", "price_level": 3, "neo4j_element_id": "dummy-b"},
            {"name": "Dummy Meyhane C", "address": "Dummy Mekan C", "rating": 3.8, "review_count": 50, "map_link": "http://dummy.map.c", "phone": "000", "price_level": 1, "neo4j_element_id": "dummy-c"},
        ]


    processed_docs = process_documents(meyhaneler_listesi)
    try:
        vectorstore = InMemoryVectorStore.from_documents(
            documents=processed_docs,
            embedding=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY) 
        )
        st.success("VektÃ¶r deposu baÅŸarÄ±yla oluÅŸturuldu.")
        return vectorstore.as_retriever(search_kwargs={"k": 5})
    except Exception as e:
        st.error(f"VektÃ¶r deposu oluÅŸturulurken hata oluÅŸtu: {e}. OpenAI API anahtarÄ±nÄ±zÄ± kontrol edin.")
        class DummyRetriever:
            def invoke(self, query, k):
                st.warning("Dummy retriever kullanÄ±lÄ±yor. GerÃ§ek arama yapÄ±lamÄ±yor.")
                return [Document(page_content="Dummy Mekan", metadata={"Mekan AdÄ±": "Dummy Mekan", "Adres": "Bilinmiyor", "Google PuanÄ±": "0.0", "Google Yorum SayÄ±sÄ±": "0", "Maps Linki": "", "Telefon": "", "Fiyat Seviyesi": ""})]
        return DummyRetriever()

retriever = initialize_retriever()


SYSTEM_PROMPT = """Sen Ä°stanbul'da romantik mekan, meyhane, restoran ve kafe Ã¶nerisi yapabilen bir AI asistanÄ±sÄ±n.
KullanÄ±cÄ±ya Google haritalar bilgileriyle desteklenmiÅŸ, hava durumuyla uyumlu Ã¶nerilerde bulunabilirsin.
Gelen sorulara doÄŸal, nazik ve samimi bir dille cevap ver ve tÃ¼m cevaplarÄ±n TÃ¼rkÃ§e olsun.

AÅŸaÄŸÄ±daki gibi konuÅŸmalar seni yÃ¶nlendirmelidir:
- 'BeÅŸiktaÅŸâ€™ta romantik bir mekan var mÄ±?' â†’ Mekan aramasÄ± yap
- 'YarÄ±n BeÅŸiktaÅŸ'ta hava nasÄ±l olacak?' â†’ Hava durumu kontrol et
- 'Bir ilginÃ§ bilgi ver' â†’ EÄŸlenceli bir bilgi paylaÅŸ
- 'Merhaba', 'Selam' â†’ KarÅŸÄ±lama mesajÄ± gÃ¶nder

KullandÄ±ÄŸÄ±n veritabanÄ±nda yer alan mekanlar sadece Ä°stanbul sÄ±nÄ±rlarÄ± iÃ§indedir.
EÄŸer kullanÄ±cÄ± baÅŸka ÅŸehirde mekan istiyorsa, bunu aÃ§Ä±kÃ§a belirtmelisin."""

SUMMARY_PROMPT = ChatPromptTemplate.from_messages([
    ("system", "Sohbet geÃ§miÅŸini kÄ±sa ve Ã¶z ÅŸekilde Ã¶zetle. Sadece Ã¶nemli bilgileri korla."),
    MessagesPlaceholder(variable_name="messages"),
])

@cached(TTLCache(maxsize=100, ttl=3600))
def get_fun_fact() -> str:
    try:
        response = requests.get("https://uselessfacts.jsph.pl/api/v2/facts/random?language=tr", timeout=5)
        response.raise_for_status() 
        fact = response.json().get("text", "Ä°lginÃ§ bir bilgi bulunamadÄ±.")
        return fact
    except requests.exceptions.Timeout:
        st.error("Ä°lginÃ§ bilgi servisi zaman aÅŸÄ±mÄ±na uÄŸradÄ±.")
        return "Ä°lginÃ§ bilgi servisi ÅŸu an Ã§ok yavaÅŸ veya Ã§alÄ±ÅŸmÄ±yor."
    except requests.exceptions.RequestException as e:
        st.error(f"Ä°lginÃ§ bilgi servisi hatasÄ±: {e}")
        return f"Ä°lginÃ§ bilgi servisi ÅŸu an Ã§alÄ±ÅŸmÄ±yor. Hata: {e}"
    except Exception as e:
        st.error(f"Ä°lginÃ§ bilgi alÄ±nÄ±rken beklenmedik hata: {e}")
        return f"Ä°lginÃ§ bilgi alÄ±nÄ±rken beklenmedik bir hata oluÅŸtu: {e}"

def clean_location_query(query: str) -> str:
    normalized_query = unicodedata.normalize('NFKD', query.lower()).encode('ascii', 'ignore').decode('utf-8')

    istanbul_locations = [
        r'etiler', r'levent', r'maslak', r'nisantasi', r'nisantaÅŸi',
        r'bebek', r'arnavutkoy', r'arnavutkÃ¶y', r'ortakoy', r'ortakÃ¶y', r'cihangir',
        r'taksim', r'karakoy', r'karakÃ¶y', r'galata', r'fatih',
        r'sultanahmet', r'eminonu', r'eminÃ¶nÃ¼', r'kadikoy', r'kadÄ±kÃ¶y', r'moda',
        r'bagdat caddesi', r'baÄŸdat caddesi', r'suadiye', r'bostanci', r'bostancÄ±',
        r'maltepe', r'kartal', r'pendik', r'uskudar', r'Ã¼skÃ¼dar',
        r'camlica', r'Ã§amlÄ±ca', r'beykoz', r'atasehir', r'ataÅŸehir', r'cekmekoy', r'Ã§ekmekÃ¶y',
        r'sariyer', r'sarÄ±yer', r'istinye', r'tarabya', r'yenikoy', r'yenikÃ¶y',
        r'bahcekoy', r'bahÃ§ekÃ¶y', r'buyukdere', r'bÃ¼yÃ¼kdere', r'zumrutevler', r'zÃ¼mrutevler',
        r'florya', r'yesilkoy', r'yeÅŸilkÃ¶y', r'yesilyurt', 'yeÅŸilyurt', r'bakirkoy', r'bakÄ±rkÃ¶y',
        r'atakoy', r'atakÃ¶y', r'zeytinburnu', r'gungoren', r'gÃ¼ngÃ¶ren', r'esenler',
        r'bayrampasa', r'bayrampaÅŸa', r'gaziosmanpasa', r'gaziosmanpaÅŸa', r'eyup', r'eyÃ¼p', r'kagithane', r'kaÄŸÄ±thane',
        r'sisli', r'ÅŸiÅŸli', r'besiktas', r'beÅŸiktaÅŸ', r'avcilar', r'avcÄ±lar', r'beylikduzu', 'beylikdÃ¼zÃ¼',
        r'esenyurt', r'buyukcekmece', r'bÃ¼yÃ¼kÃ§ekmece', r'silivri', r'catalca', r'Ã§atalca',
        r'sile', r'ÅŸile', r'agva', r'aÄŸva', r'adalar', r'basaksehir', 'baÅŸakÅŸehir',
        r'bahcelievler', r'bahÃ§elievler', r'kucukcekmece', r'kÃ¼Ã§Ã¼kÃ§ekmece', r'cankurtaran'
    ]

    for loc_regex in istanbul_locations:
        match = re.search(r'\b' + loc_regex + r'\b', normalized_query)
        if match:
            return match.group(0)

    general_cities = [
        r'istanbul', r'ankara', r'izmir', r'adana',
        r'bursa', r'antalya', r'konya', r'kayseri',
        r'gaziantep', r'samsun', r'eskisehir', r'eskiÅŸehir', r'duzce', r'dÃ¼zce'
    ]

    for city_regex in general_cities:
        match = re.search(r'\b' + city_regex + r'\b', normalized_query)
        if match:
            return match.group(0)

    return "istanbul"

weather_cache = TTLCache(maxsize=100, ttl=300)

@cached(weather_cache)
def get_openweather_forecast(location: str) -> Dict:
    api_key = st.secrets.get("OPENWEATHER_API_KEY") # Corrected
    if not api_key:
        st.error("OpenWeather API anahtarÄ± bulunamadÄ±.")
        return {"error": "API anahtarÄ± bulunamadÄ±."}
    try:
        geo_response = requests.get(
            f"http://api.openweathermap.org/geo/1.0/direct?q={location},TR&limit=1&appid={api_key}",
            timeout=10,
        )
        geo_response.raise_for_status()
        geo = geo_response.json()
        if not geo:
            st.warning(f"'{location}' konumu iÃ§in coÄŸrafi veri bulunamadÄ±.")
            return {"error": f"'{location}' konumu bulunamadÄ±."}
        lat, lon = geo[0]["lat"], geo[0]["lon"]
        weather_response = requests.get(
            f"https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={api_key}&units=metric&lang=tr",
            timeout=10,
        )
        weather_response.raise_for_status()
        weather = weather_response.json()
        return weather
    except requests.exceptions.RequestException as e:
        st.error(f"OpenWeather API hatasÄ±: {e}")
        return {"error": f"API hatasÄ±: {e}"}
    except Exception as e:
        st.error(f"Hava durumu verisi alÄ±nÄ±rken beklenmedik hata: {e}")
        return {"error": f"Beklenmedik bir hata oluÅŸtu: {e}"}

def format_weather_response(location: str, data: Dict) -> str:
    if "error" in data:
        st.error(f"Hava durumu formatlama hatasÄ±: {data['error']}")
        return f"âŒ {data['error']}"
    try:
        lines = [f"ğŸŒ¤ï¸ **{location.capitalize()} Hava Durumu Tahmini:**"]
        if "list" not in data or not data["list"]:
            st.warning("Hava durumu verisi eksik veya boÅŸ.")
            return f"âŒ {location} iÃ§in hava durumu verisi bulunamadÄ±."

        today = datetime.now().date()
        daily_forecasts = {}

        for item in data["list"]:
            timestamp = item["dt"]
            forecast_time = datetime.fromtimestamp(timestamp)
            forecast_date = forecast_time.date()

            # Sadece bugÃ¼nden sonraki veya bugÃ¼nÃ¼ kapsayan 5 gÃ¼nlÃ¼k tahmini al
            if forecast_date >= today and len(daily_forecasts) < 5:
                date_str = "BugÃ¼n" if forecast_date == today else forecast_time.strftime("%d %B")
                temp = item["main"]["temp"]
                description = item["weather"][0]["description"]
                icon_code = item["weather"][0]["icon"]
                icon_url = f"http://openweathermap.org/img/wn/{icon_code}.png"

                if forecast_date not in daily_forecasts:
                    daily_forecasts[forecast_date] = {
                        "date_str": date_str,
                        "temps": [],
                        "descriptions": set(),
                        "icons": set()
                    }
                daily_forecasts[forecast_date]["temps"].append(temp)
                daily_forecasts[forecast_date]["descriptions"].add(description)
                daily_forecasts[forecast_date]["icons"].add(icon_url)

        for date, forecast in daily_forecasts.items():
            avg_temp = sum(forecast["temps"]) / len(forecast["temps"])
            descriptions = ", ".join(list(forecast["descriptions"]))
            lines.append(
                f"- **{forecast['date_str']}**: SÄ±caklÄ±k: {avg_temp:.1f}Â°C, Durum: {descriptions.capitalize()}."
            )

        return "\n".join(lines)
    except Exception as e:
        st.error(f"Hava durumu yanÄ±tÄ± formatlanÄ±rken beklenmedik hata: {e}")
        return f"âŒ Hava durumu bilgisi formatlanÄ±rken bir hata oluÅŸtu: {e}"

class Tools:
    def __init__(self, llm_model, retriever):
        self.llm_model = llm_model
        self.retriever = retriever


    def search_places(self, state: AgentState) -> List[Document]:
        st.info("Mekan arama aracÄ± Ã§aÄŸrÄ±ldÄ±...")
        messages = state['messages']
        query = messages[-1].content
        clean_query = clean_location_query(query)

        retrieved_docs = self.retriever.invoke(clean_query, k=5)
        st.success(f"{len(retrieved_docs)} mekan bulundu.")
        return retrieved_docs

    def get_weather_forecast(self, state: AgentState) -> str:
        st.info("Hava durumu aracÄ± Ã§aÄŸrÄ±ldÄ±...")
        messages = state['messages']
        query = messages[-1].content
        location = clean_location_query(query) 
        
        weather_data = get_openweather_forecast(location)
        formatted_weather = format_weather_response(location, weather_data)
        st.success(f"{location} iÃ§in hava durumu bilgisi Ã§ekildi.")
        return formatted_weather

    def provide_fun_fact(self, state: AgentState) -> str:
        st.info("Ä°lginÃ§ bilgi aracÄ± Ã§aÄŸrÄ±ldÄ±...")
        return get_fun_fact()

    def generate_response(self, state: AgentState) -> str:
        st.info("YanÄ±t oluÅŸturma aracÄ± Ã§aÄŸrÄ±ldÄ±...")
        messages = state['messages']

        user_message_content = messages[-1].content
        retrieved_docs = self.retriever.invoke(user_message_content, k=5) 

        context_str = "\n".join([doc.page_content for doc in retrieved_docs])
        if context_str:
            st.info(f"YanÄ±t oluÅŸturmak iÃ§in {len(retrieved_docs)} dokÃ¼man kullanÄ±lÄ±yor.")
            full_prompt = ChatPromptTemplate.from_messages([
                ("system", SYSTEM_PROMPT + "\n\nKullanÄ±labilecek ek bilgi/mekanlar:\n" + context_str),
                MessagesPlaceholder(variable_name="messages"),
            ])
        else:
            st.warning("Mekan Ã¶nerisi iÃ§in uygun dokÃ¼man bulunamadÄ±, genel prompt kullanÄ±lÄ±yor.")
            full_prompt = ChatPromptTemplate.from_messages([
                ("system", SYSTEM_PROMPT),
                MessagesPlaceholder(variable_name="messages"),
            ])
        
        try:
            response = self.llm_model.invoke(full_prompt.format_messages(messages=messages))
            st.success("YanÄ±t baÅŸarÄ±yla oluÅŸturuldu.")
            return response.content
        except Exception as e:
            st.error(f"YanÄ±t oluÅŸturulurken hata oluÅŸtu: {e}")
            return "ÃœzgÃ¼nÃ¼m, ÅŸu an bir yanÄ±t oluÅŸturamÄ±yorum."

    def summarize_conversation(self, state: AgentState) -> str:
        st.info("Sohbet Ã¶zetleme aracÄ± Ã§aÄŸrÄ±ldÄ±...")
        messages = state['messages']
        recent_messages = messages[-5:]
        try:
            summary_response = self.llm_model.invoke(SUMMARY_PROMPT.format_messages(messages=recent_messages))
            st.success("Sohbet Ã¶zeti oluÅŸturuldu.")
            return summary_response.content
        except Exception as e:
            st.error(f"Sohbet Ã¶zetlenirken hata oluÅŸtu: {e}")
            return "Sohbet Ã¶zetlenemedi."

    def route_question(self, state: AgentState) -> str:
        st.info("Soru yÃ¶nlendirme aracÄ± Ã§aÄŸrÄ±ldÄ±...")
        messages = state["messages"]
        last_message = messages[-1]

        if "hava" in last_message.content.lower() or "sÄ±caklÄ±k" in last_message.content.lower():
            st.success("Hava durumu rotasÄ±na yÃ¶nlendiriliyor.")
            return "weather"
        if "ilginÃ§ bilgi" in last_message.content.lower() or "bilgi ver" in last_message.content.lower():
            st.success("Ä°lginÃ§ bilgi rotasÄ±na yÃ¶nlendiriliyor.")
            return "fun_fact"
        if "Ã¶zetle" in last_message.content.lower() or "Ã¶zet" in last_message.content.lower():
            st.success("Ã–zetleme rotasÄ±na yÃ¶nlendiriliyor.")
            return "summarize"
        
        place_keywords = ["mekan", "restoran", "kafe", "meyhane", "nereye gideyim", "Ã¶neri", "yer"]
        if any(keyword in last_message.content.lower() for keyword in place_keywords):
            st.success("Mekan arama rotasÄ±na yÃ¶nlendiriliyor.")
            return "search_places"

        st.success("Genel yanÄ±t rotasÄ±na yÃ¶nlendiriliyor.")
        return "generate_response" 


def create_workflow():
    st.info("LangGraph iÅŸ akÄ±ÅŸÄ± oluÅŸturuluyor...")
    workflow = StateGraph(AgentState)

    llm = ChatOpenAI(model="gpt-4o", temperature=0, openai_api_key=OPENAI_API_KEY)
    tools = Tools(llm_model=llm, retriever=retriever)

    workflow.add_node("route_question", tools.route_question)
    workflow.add_node("search_places", tools.search_places)
    workflow.add_node("get_weather_forecast", tools.get_weather_forecast)
    workflow.add_node("provide_fun_fact", tools.provide_fun_fact)
    workflow.add_node("generate_response", tools.generate_response)
    workflow.add_node("summarize_conversation", tools.summarize_conversation)

    workflow.set_entry_point("route_question")

    workflow.add_conditional_edges(
        "route_question",
        lambda state: state["next_node"] if state.get("next_node") else state["messages"][-1].content, # HACK: Use content for routing
        {
            "search_places": "search_places",
            "weather": "get_weather_forecast",
            "fun_fact": "provide_fun_fact",
            "summarize": "summarize_conversation",
            "generate_response": "generate_response",
        },
    )

    workflow.add_edge("search_places", "generate_response")
    workflow.add_edge("get_weather_forecast", "generate_response")
    workflow.add_edge("provide_fun_fact", "generate_response")
    workflow.add_edge("summarize_conversation", "generate_response")
    
    workflow.add_edge("generate_response", END)

    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)
    st.success("LangGraph iÅŸ akÄ±ÅŸÄ± baÅŸarÄ±yla oluÅŸturuldu.")
    return app

# --- Streamlit UygulamasÄ± ---
st.set_page_config(page_title="Ä°stanbul Mekan AsistanÄ±", layout="wide")
st.title("Ä°stanbul Mekan ve Hava Durumu AsistanÄ± ğŸ“")


if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"], unsafe_allow_html=True)


if prompt := st.chat_input("NasÄ±l yardÄ±mcÄ± olabilirim?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.spinner("YanÄ±t oluÅŸturuluyor..."):
        app = create_workflow()
        

        if "conversation_thread_id" not in st.session_state:
            st.session_state.conversation_thread_id = str(uuid.uuid4())
            
        
        config = {"configurable": {"thread_id": st.session_state.conversation_thread_id}}

        response_placeholder = st.empty() 
        latest_ai_message_content = ""

        try:
            for s in app.stream({"messages": [HumanMessage(content=prompt)]}, config=config):
                for key in s:
                    node_output = s[key]
                    if "messages" in node_output:
                        for msg in reversed(node_output["messages"]):
                            if isinstance(msg, AIMessage) and msg.content:
                                latest_ai_message_content = msg.content
                                break 


 
            if latest_ai_message_content:
                sanitized_content = sanitize_markdown(latest_ai_message_content)
                st.session_state.messages.append({"role": "assistant", "content": sanitized_content})
                
                with st.chat_message("assistant"):
                    st.markdown(sanitized_content, unsafe_allow_html=True)
            else:
                error_msg = "ÃœzgÃ¼nÃ¼m, bir yanÄ±t Ã¼retemedim. LangGraph akÄ±ÅŸÄ± tamamlandÄ± ancak AI mesajÄ± bulunamadÄ±. LÃ¼tfen tekrar deneyin."
                st.session_state.messages.append({"role": "assistant", "content": error_msg})
                with st.chat_message("assistant"):
                    st.markdown(error_msg)
                st.error("LangGraph akÄ±ÅŸÄ± AI mesajÄ± Ã¼retmeden tamamlandÄ±.")

        except Exception as e:
            error_message = f"Bir hata oluÅŸtu: {e}. LÃ¼tfen daha sonra tekrar deneyin."
            st.error(f"Ana dÃ¶ngÃ¼de beklenmedik hata: {str(e)}")
            print(f"ERROR in main loop: {str(e)}")
            st.session_state.messages.append({"role": "assistant", "content": error_message})
            with st.chat_message("assistant"):
                st.markdown(error_message)
                st.exception(e)  
    st.rerun()